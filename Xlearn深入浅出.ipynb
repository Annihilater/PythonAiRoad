{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829d239c-710c-4ae8-ba43-3f2f8d7673dc",
   "metadata": {},
   "source": [
    "# Xlearn 深入浅出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea5b2b-03cc-4d90-903a-f9fee0e82df6",
   "metadata": {},
   "source": [
    "xLearn 是一款高性能(C++内核，多进程)，易用的(支持Python/R和命令行，Python支持sklearn接口)，\n",
    "\n",
    "并且可扩展(可以用外存计算)的开源机器学习算法库。\n",
    "\n",
    "xlearn 常用于广告点击率预测、推荐系统等场景。\n",
    "\n",
    "xLearn 一般用于解决二分类问题和回归问题。主要支持以下三种模型。\n",
    "\n",
    "* LR(Linear Regression): 线性回归/逻辑回归。LR无法直接捕捉特征之间的交叉，适合作为Baseline使用。工业应用场景中可以根据业务理解手工设计出有效的特征交叉。也可以利用树模型的叶子节点的特征分裂规则自动产生高阶交叉特征输送给LR。\n",
    "\n",
    "*  FM(FactorizationMachine)：在LR基础上用隐向量点积实现自动化特征二阶交叉，且交互项的计算复杂度是O(n)，效果显著好于LR，速度极快接近LR。\n",
    "\n",
    "*  FFM(Field Aware FM): 在FM的基础上考虑对不同的特征域(Field，可以理解成特征的分组)使用不同的隐向量。效果好于FM，但参数量增加，预测速度下降。\n",
    "\n",
    "公众号算法美食屋 后台回复关键词 xlearn, 下载本范例所用广告点击率预测 数据集 criteo_small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6f14d-b569-4090-84b3-4355ea6bb5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4f51f3d-54f5-4804-9251-9ca8ce2ef49b",
   "metadata": {},
   "source": [
    "## 〇，安装Xlearn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c130615-1d9e-4b8d-a082-c5ad33a946d3",
   "metadata": {},
   "source": [
    "xlearn依赖gcc和cmake。linux环境可以用apt-get安装。\n",
    "\n",
    "依赖安装好后，可以直接用pip安装xlearn。也可以git克隆下最新源码进行一键安装。\n",
    "\n",
    "推荐使用git clone下源码的安装方式，版本更新，并且可以download下git项目中的范例数据集和代码。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9c988-030b-426c-adff-c036c63875f1",
   "metadata": {},
   "source": [
    "### 1，安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c7106-4105-4daf-820f-b34f695754ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc --version #查看gcc是否存在，一般都是存在的\n",
    "#!yes|apt-get install gcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97131e19-25c9-46b0-9504-6d8524071b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!yes|apt-get install cmake\n",
    "!pip install cmake "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5228fa-5d09-4041-9987-3bc0f56fce6f",
   "metadata": {},
   "source": [
    "### 2，安装xlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98e51d-725c-406a-b369-673febdc9eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#直接pip安装\n",
    "#!pip install xlearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59d546-eea2-4b45-9bc5-05596fd04c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#从源码下载最新版本，然后一键安装\n",
    "!git clone https://github.com/aksnzhy/xlearn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c26fe-44d3-4f56-86c6-98ba97da3949",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd xlearn\n",
    "./build.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc9c57-bdbe-40ee-8c09-eed9d736242a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "145608b3-837c-4408-b3ca-e95b4a3a8336",
   "metadata": {},
   "source": [
    "### 3，检验是否安装成功"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c83659-f26e-4283-9dd0-e5bb0446cbba",
   "metadata": {},
   "source": [
    "我们通过一个非常简单的xlearn的sklearn接口 \n",
    "\n",
    "进行iris花瓣分类问题建模来测试xlearn是否安装成功 。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "19490bf5-fa1f-4631-aff4-d9dfa15fcdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.44 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 4\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 0.02 KB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            1.463600            2.494109            0.116310                0.02\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            1.504232            2.225566            0.978610                0.01\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            1.722561            0.460083            0.986631                0.01\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            1.571406            0.761383            0.868984                0.01\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            1.158262            1.304717            0.981283                0.01\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            1.287939            0.680796            0.986631                0.01\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            1.496729            2.397559            0.973262                0.01\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            1.286119            1.731796            0.973262                0.01\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            1.208732            0.386593            0.989305                0.01\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            1.771266            1.056444            0.893048                0.01\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 9, best AUC: 0.989305\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: /tmp/tmpx4aqadsd\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save txt model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mTXT Model file: /tmp/tmpz0e2hp78\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving txt model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 0.12 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.44 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from /tmp/tmpx4aqadsd\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: linear\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 4\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 0.00 (sec)\u001b[0m\n",
      "val_auc= 0.9919786096256684\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['USER'] = 'test' #没有USER环境变量可能会报错\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xlearn as xl\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score \n",
    "\n",
    "#1，准备数据\n",
    "dfiris = load_iris()\n",
    "X,y = dfiris['data'],(dfiris['target'] == 2)\n",
    "X_train,  X_val, y_train,y_val = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#2，定义模型\n",
    "model = xl.LRModel(task='binary', init=0.1,\n",
    "        epoch=10, lr=0.1, reg_lambda=1.0)\n",
    "\n",
    "#3，训练模型\n",
    "model.fit(X_train, y_train,\n",
    "          eval_set=[X_val, y_val])\n",
    "\n",
    "#4，使用模型\n",
    "y_pred = model.predict(X_val)\n",
    "val_auc =  roc_auc_score(y_val.astype(float),y_pred)\n",
    "print('val_auc=',auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a9d1c4-1a2e-4c19-a0a0-a1c328d2f659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "060c5af6-7c27-47ad-9a7b-65760a52024e",
   "metadata": {},
   "source": [
    "## 一， 回归问题范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb9253-541c-476f-84b5-9bd7225f0601",
   "metadata": {},
   "source": [
    "下面我们使用房价预测范例来演示使用xlearn来解决回归问题。\n",
    "\n",
    "我们将使用xlearn的原生接口xl.create_fm()来构建模型，\n",
    "\n",
    "使用xl.DMatrix来准备数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ffe6d-3607-4aab-a8d4-43df086b88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USER'] = 'test' #没有USER环境变量可能会报错\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import xlearn as xl\n",
    "\n",
    "#1，准备数据  \n",
    "dfdata = pd.read_csv(\"xlearn/demo/regression/house_price/house_price_train.txt\", \n",
    "                      header=None, sep=\"\\t\")\n",
    "dftrain,dfval = train_test_split(dfdata,test_size=200)\n",
    "dftest = pd.read_csv(\"xlearn/demo/regression/house_price/house_price_test.txt\", \n",
    "                     header=None, sep=\"\\t\")\n",
    "\n",
    "Xtrain,ytrain = dftrain[dftrain.columns[1:]],dftrain[0]\n",
    "Xval,yval = dfval[dfval.columns[1:]],dfval[0]\n",
    "Xtest,ytest = dftest[dftest.columns[1:]],dftest[0]\n",
    "dm_train = xl.DMatrix(Xtrain, ytrain)\n",
    "dm_val = xl.DMatrix(Xval, yval)\n",
    "dm_test = xl.DMatrix(Xtest, ytest)\n",
    "\n",
    "# 2，定义模型\n",
    "model = xl.create_fm()    #xl.create_linear(), xl.create_ffm()\n",
    "model.setTrain(dm_train)   \n",
    "model.setValidate(dm_val)\n",
    "param = {'task':'reg', #task 可以为 'binary' 或者 'reg', \n",
    "         'lr':0.2, \n",
    "         'lambda':0.002,  #参数L2正则系数\n",
    "         'metric':'mae',\n",
    "         'nthread':8, #使用线程数\n",
    "         'epoch':20,\n",
    "         'stop_window':10 #10个epoch未提升早停\n",
    "        }\n",
    "\n",
    "# 3，训练模型\n",
    "model_path = \"./model.out\"\n",
    "model.fit(param, model_path)\n",
    "\n",
    "# 4，验证模型\n",
    "model.setTest(dm_train)\n",
    "yhat_train = model.predict(model_path)\n",
    "train_acc = 1- np.abs(yhat_train-ytrain).sum()/np.abs(0.5*(yhat_train+ytrain)).sum()\n",
    "\n",
    "model.setTest(dm_val)\n",
    "yhat_val = model.predict(model_path)\n",
    "val_acc = 1- np.abs(yhat_val-yval).sum()/np.abs(0.5*(yhat_val+yval)).sum()\n",
    "\n",
    "print('\\n'*5+'='*80)\n",
    "print('train_acc =',train_acc)\n",
    "print('val_acc =',val_acc)\n",
    "print('='*80+'\\n'*5)\n",
    "\n",
    "# 5，使用模型\n",
    "#(模型已经保存在model_path了，可以直接加载预测)\n",
    "import xlearn as xl\n",
    "model_loaded = xl.create_fm() \n",
    "model_loaded.setTest(\"xlearn/demo/regression/house_price/house_price_test.txt\")\n",
    "out_path = './ypred.txt'\n",
    "model_loaded.predict(model_path,out_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7e496-0799-456c-a3b9-c94139028512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d08eb894-58d8-422d-90b2-8ad7b2fb2e64",
   "metadata": {},
   "source": [
    "## 二， 分类问题范例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a77aa9e-ba18-47da-8af4-99f9bfb2d182",
   "metadata": {},
   "source": [
    "我们以使用FFM算法处理Criteo广告点击率预测问题为例，展示xlearn的处理分类问题的典型流程。\n",
    "\n",
    "Criteo数据集是一个经典的广告点击率CTR预测数据集。\n",
    "\n",
    "这个数据集的目标是通过用户特征和广告特征来预测某条广告是否会为用户点击。\n",
    "\n",
    "数据集有13维数值特征(I1~I13)和26维类别特征(C14~C39), 共39维特征, 特征中包含着许多缺失值。\n",
    "\n",
    "训练集4000万个样本，测试集600万个样本。数据集大小超过100G.\n",
    "\n",
    "此处使用的是采样100万个样本后的criteo_small数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaf65b7-c756-4342-9098-6a900dce0983",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba263e11-6ff6-426c-b440-7cb8801de0bd",
   "metadata": {},
   "source": [
    "### 1，准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a1871-8a63-4738-b78a-f3c44caab280",
   "metadata": {},
   "source": [
    "Xlearn为FFM模型组织数据集最高效的方法是将数据整理成libffm格式。\n",
    "\n",
    "libffm格式是专门为FFM算法设计的一种txt数据格式，当然这种格式也支持Xlearn中的FM模型和LR模型。\n",
    "\n",
    "libffm格式的每一行是一条样本，按照如下格式排布。\n",
    "\n",
    "```\n",
    "label  field1:feature1:value1  field1:feature2:value2  field2:feature3:value3  \n",
    "```\n",
    "在FFM相关的模型中，有field(阈)和feature(特征)的概念区分，一个field可以对应一个或者多个features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "523c0dd4-d385-4959-a1be-287f766d74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm.auto import tqdm\n",
    "class CatEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_features, max_dictionary_size=200):\n",
    "        self.cat_features = cat_features\n",
    "        self.max_dictionary_size = max_dictionary_size \n",
    "        self.trans_dics = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in tqdm(self.cat_features):\n",
    "            Xcol = self._fillna(X[col])\n",
    "            self.trans_dics[col] = self._get_trans_dic(Xcol)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        Xs = [self._fillna(X[col]).apply(lambda a:self.trans_dics[col].get(a,0))\n",
    "             for col in self.cat_features]\n",
    "        return pd.concat(Xs,axis=1).values \n",
    "    \n",
    "    def _fillna(self, seri):\n",
    "        return seri.astype(str).fillna(\"nan\")\n",
    "    \n",
    "    def _get_trans_dic(self,seri):\n",
    "        max_dictionary_size = self.max_dictionary_size\n",
    "        dfi = pd.DataFrame(seri.value_counts()).rename(lambda _:\"count\",axis = 1)\n",
    "        dfi.sort_values(\"count\",ascending=False,inplace = True)\n",
    "        \n",
    "        n = len(dfi)\n",
    "        if n<=max_dictionary_size:\n",
    "            dfi[\"index\"] = range(n)\n",
    "        else:\n",
    "            cum = np.cumsum(dfi[\"count\"])\n",
    "            cum = cum/cum.iloc[-1]\n",
    "            cum_split = cum.iloc[max_dictionary_size//2]\n",
    "            get_index = lambda i: i if cum.iloc[i]<=cum_split else max_dictionary_size//2 + int(\n",
    "                (max_dictionary_size-max_dictionary_size//2)*(cum.iloc[i]-cum_split-1e-12)/(1-cum_split))\n",
    "            dfi[\"index\"] = [get_index(i) for i in range(n)]\n",
    "\n",
    "        trans_dic = dict(dfi[\"index\"])  \n",
    "        return trans_dic\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return self.cat_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1a1ab6df-2560-4bba-bf0c-b7d4b78d7ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d41d9b8585a436385c5e536a4bf9934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81fe038a03a34a89abd3846043b02fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,QuantileTransformer,KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "dfdata = pd.read_csv(\"criteo_small.zip\",sep=\"\\t\",header=None)\n",
    "dfdata.columns = [\"label\"] + [\"I\"+str(x) for x in range(1,14)] + [\n",
    "    \"C\"+str(x) for x in range(14,40)]\n",
    "\n",
    "label_col = 'label'\n",
    "cat_cols = [x for x in dfdata.columns if x.startswith('C')]\n",
    "num_cols = [x for x in dfdata.columns if x.startswith('I')]\n",
    "\n",
    "dfdata[cat_cols]  = CatEncoder(cat_features = cat_cols\n",
    "                    ).fit_transform(dfdata[cat_cols])\n",
    "dfdata[num_cols] = SimpleImputer().fit_transform(dfdata[num_cols])\n",
    "\n",
    "for col in tqdm(num_cols):\n",
    "    unique_value_cnt = len(np.unique(dfdata[col]))\n",
    "    if unique_value_cnt<100:\n",
    "        dfdata['C'+col] = LabelEncoder().fit_transform(dfdata[col])\n",
    "    else:\n",
    "        kbins = KBinsDiscretizer(n_bins=20,encode='ordinal',strategy='kmeans')\n",
    "        dfdata['C'+col] = kbins.fit_transform(dfdata[[col]])[:,0].astype(int)\n",
    "        \n",
    "dfdata[num_cols] = QuantileTransformer().fit_transform(dfdata[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c7236ec8-7f88-4526-8afa-70b16282c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dftrain_val,dftest = train_test_split(dfdata,test_size=0.2)\n",
    "dftrain,dfval = train_test_split(dftrain_val,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "ff80f996-c4a9-4420-a0e4-afdacdea8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 'label'\n",
    "cat_cols = [x for x in dfdata.columns if x.startswith('C')]\n",
    "num_cols = [x for x in dfdata.columns if x.startswith('I')]\n",
    "\n",
    "field_features = defaultdict()\n",
    "categories = num_cols+cat_cols\n",
    "categories_index = dict(zip(categories, range(len(categories))))\n",
    "max_val = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "eadf3009-e63b-4fc4-a1de-835836492ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_libffm(df,save_file='train.libffm'):\n",
    "    from tqdm.auto import tqdm \n",
    "    global max_val\n",
    "    global label_col\n",
    "    with open(save_file, 'a') as the_file:\n",
    "        for t in tqdm(range(len(df))):\n",
    "            row = df.iloc[t]\n",
    "            label = [str(int(row[label_col]))]\n",
    "            ffeatures = []\n",
    "            for field in categories:\n",
    "                if field == label_col:\n",
    "                    continue \n",
    "                feature = row[field]\n",
    "                if field not in num_cols:\n",
    "                    ff = field + '_____' + str(feature)\n",
    "                    value = 1\n",
    "                else:\n",
    "                    ff = field + '_____' + str(0)\n",
    "                    value = feature\n",
    "\n",
    "                if ff not in field_features:\n",
    "                    if len(field_features) == 0:\n",
    "                        field_features[ff] = 1\n",
    "                        max_val = max_val+1\n",
    "                    else:\n",
    "                        field_features[ff] = max_val + 1\n",
    "                        max_val = max_val+1\n",
    "                fnum = field_features[ff]\n",
    "                ffeatures.append('{}:{}:{}'.format(categories_index[field],fnum,value))\n",
    "            line = label + ffeatures\n",
    "            the_file.write('{}\\n'.format(' '.join(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "e4f2829d-ac60-43cb-a448-aa4b3901b0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ef3df97d5f42c1aac5b188020ebe6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/640000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_to_libffm(dftrain,'train.libffm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5d5e002f-1067-425d-956e-40b8007d49ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172040e02f824ef294fbd5f57739e890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_to_libffm(dfval,'val.libffm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "680d19d4-dd25-4a41-953e-d7c9ff80fc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ef5306c98d418daf60fecf0a353c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_to_libffm(dftest,'test.libffm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "824e4432-eb1f-4683-b8d3-ff79e51c7658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4012"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(field_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc80a5-5c61-4697-920b-cfecdd5baa0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46f19f52-262c-4fec-a3f6-2b1f68b80e92",
   "metadata": {},
   "source": [
    "### 2， 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "aaf62477-65f0-4754-825f-056fd29bcc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_ffm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_ffm.py\n",
    "import os\n",
    "os.environ['USER'] = 'test' #没有USER环境变量可能会报错\n",
    "import xlearn as xl\n",
    "model = xl.create_ffm()  \n",
    "model.setTrain('train.libffm')   \n",
    "model.setValidate('val.libffm')\n",
    "#model.disableNorm()\n",
    "#model.disableEarlyStop()\n",
    "param = {'task':'binary', 'lr':0.05, 'lambda':0.000, 'nthread':64,  'epoch':200,\n",
    "         'stop_window':15, 'metric':'auc'}\n",
    "model_path = \"./model.out\"\n",
    "model.fit(param, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ae4f1-53cd-4951-8447-12b8e923a0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f392d33-c868-4589-ad34-ab9fdacce19f",
   "metadata": {},
   "source": [
    "### 3，训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "da113358-0c50-45d0-8601-63f9f19a6508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.44 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 64 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.libffm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.libffm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 4002\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 52\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 5.02 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 6.38 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.08 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   0%\u001b[32m      ]\u001b[0m     1            0.494201            0.485155            0.754214               29.89\n",
      "\u001b[32m[ \u001b[0m   1%\u001b[32m      ]\u001b[0m     2            0.482604            0.480413            0.760468               30.01\n",
      "\u001b[32m[ \u001b[0m   1%\u001b[32m      ]\u001b[0m     3            0.478454            0.477617            0.764349               29.59\n",
      "\u001b[32m[ \u001b[0m   2%\u001b[32m      ]\u001b[0m     4            0.475699            0.475635            0.767053               29.89\n",
      "\u001b[32m[ \u001b[0m   2%\u001b[32m      ]\u001b[0m     5            0.473661            0.474323            0.768579               30.00\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     6            0.472014            0.473253            0.770017               29.30\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     7            0.470593            0.472334            0.771192               29.69\n",
      "\u001b[32m[ \u001b[0m   4%\u001b[32m      ]\u001b[0m     8            0.469272            0.471535            0.772265               30.30\n",
      "\u001b[32m[ \u001b[0m   4%\u001b[32m      ]\u001b[0m     9            0.468016            0.470867            0.773180               30.30\n",
      "\u001b[32m[ \u001b[0m   5%\u001b[32m      ]\u001b[0m    10            0.466797            0.470201            0.774062               31.21\n",
      "\u001b[32m[ \u001b[0m   5%\u001b[32m      ]\u001b[0m    11            0.465585            0.469643            0.774855               30.39\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m    12            0.464379            0.468920            0.775686               31.20\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m    13            0.463163            0.468457            0.776328               30.59\n",
      "\u001b[32m[ \u001b[0m   7%\u001b[32m      ]\u001b[0m    14            0.461951            0.467863            0.776997               29.51\n",
      "\u001b[32m[ \u001b[0m   7%\u001b[32m      ]\u001b[0m    15            0.460705            0.467326            0.777737               29.80\n",
      "\u001b[32m[ \u001b[0m   8%\u001b[32m      ]\u001b[0m    16            0.459483            0.466951            0.778322               30.29\n",
      "\u001b[32m[ \u001b[0m   8%\u001b[32m      ]\u001b[0m    17            0.458252            0.466495            0.778804               31.20\n",
      "\u001b[32m[ \u001b[0m   9%\u001b[32m      ]\u001b[0m    18            0.457022            0.466027            0.779369               30.99\n",
      "\u001b[32m[ \u001b[0m   9%\u001b[32m      ]\u001b[0m    19            0.455785            0.465830            0.779832               30.92\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m    20            0.454562            0.465633            0.780153               30.39\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m    21            0.453334            0.465144            0.780504               30.48\n",
      "\u001b[32m[ \u001b[0m  11%\u001b[32m      ]\u001b[0m    22            0.452106            0.464915            0.780775               23.30\n",
      "\u001b[32m[ \u001b[0m  11%\u001b[32m      ]\u001b[0m    23            0.450926            0.464725            0.781038               16.02\n",
      "\u001b[32m[ \u001b[0m  12%\u001b[32m      ]\u001b[0m    24            0.449745            0.464609            0.781271               16.20\n",
      "\u001b[32m[ \u001b[0m  12%\u001b[32m      ]\u001b[0m    25            0.448581            0.464399            0.781469               16.19\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m    26            0.447410            0.464402            0.781481               16.22\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m    27            0.446269            0.464257            0.781665               16.22\n",
      "\u001b[32m[ \u001b[0m  14%\u001b[32m      ]\u001b[0m    28            0.445129            0.464235            0.781712               16.11\n",
      "\u001b[32m[ \u001b[0m  14%\u001b[32m      ]\u001b[0m    29            0.443987            0.464194            0.781788               15.99\n",
      "\u001b[32m[ \u001b[0m  15%\u001b[32m      ]\u001b[0m    30            0.442862            0.464208            0.781803               16.10\n",
      "\u001b[32m[ \u001b[0m  15%\u001b[32m      ]\u001b[0m    31            0.441747            0.464204            0.781812               16.14\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m    32            0.440636            0.464260            0.781752               16.20\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m    33            0.439535            0.464327            0.781701               16.07\n",
      "\u001b[32m[ \u001b[0m  17%\u001b[32m      ]\u001b[0m    34            0.438437            0.464443            0.781589               15.99\n",
      "\u001b[32m[ \u001b[0m  17%\u001b[32m      ]\u001b[0m    35            0.437349            0.464577            0.781560               16.07\n",
      "\u001b[32m[ \u001b[0m  18%\u001b[32m      ]\u001b[0m    36            0.436250            0.464638            0.781451               15.94\n",
      "\u001b[32m[ \u001b[0m  18%\u001b[32m      ]\u001b[0m    37            0.435185            0.464884            0.781381               16.05\n",
      "\u001b[32m[ \u001b[0m  19%\u001b[32m      ]\u001b[0m    38            0.434115            0.464931            0.781228               16.07\n",
      "\u001b[32m[ \u001b[0m  19%\u001b[32m      ]\u001b[0m    39            0.433085            0.465063            0.781097               15.77\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m    40            0.432020            0.465244            0.780893               15.92\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m    41            0.430975            0.465416            0.780802               15.97\n",
      "\u001b[32m[ \u001b[0m  21%\u001b[32m      ]\u001b[0m    42            0.429933            0.465621            0.780607               16.20\n",
      "\u001b[32m[ \u001b[0m  21%\u001b[32m      ]\u001b[0m    43            0.428911            0.465922            0.780420               16.25\n",
      "\u001b[32m[ \u001b[0m  22%\u001b[32m      ]\u001b[0m    44            0.427885            0.466026            0.780218               16.33\n",
      "\u001b[32m[ \u001b[0m  22%\u001b[32m      ]\u001b[0m    45            0.426882            0.466237            0.780091               16.10\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m    46            0.425871            0.466488            0.779882               16.03\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m    47            0.424862            0.466721            0.779716               15.99\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 31, best AUC: 0.781812\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: ./model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 1066.56 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train_ffm.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd2137-9ef3-48a9-bfa3-ece805c48629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66415384-b6db-46cc-84c1-51548b53e8a8",
   "metadata": {},
   "source": [
    "### 4，验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "40a9fd2c-003a-4327-a966-a31417541b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.44 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 96 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from ./model.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 4002\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 52\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.libffm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.59 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.440156\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 0.80 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.44 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 96 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from ./model.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 4002\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 52\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.libffm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.16 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.464204\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 0.19 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.44 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 96 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from ./model.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 4002\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 52\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.libffm.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.18 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.466015\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 0.22 (sec)\u001b[0m\n",
      "train_auc =  0.8119066807295718\n",
      "val_auc =  0.7818116270759282\n",
      "test_auc =  0.7795088107280506\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import roc_auc_score \n",
    "os.environ['USER'] = 'test' #没有USER环境变量可能会报错\n",
    "import xlearn as xl\n",
    "model = xl.create_ffm()  \n",
    "model.setSigmoid()\n",
    "model_path = \"./model.out\"\n",
    "\n",
    "model.setTest('train.libffm')\n",
    "yhat_train = model.predict(model_path)\n",
    "\n",
    "model.setTest('val.libffm')\n",
    "yhat_val = model.predict(model_path)\n",
    "\n",
    "\n",
    "model.setTest('test.libffm')\n",
    "yhat_test = model.predict(model_path)\n",
    "\n",
    "train_auc = roc_auc_score(ytrain.values,yhat_train)\n",
    "val_auc = roc_auc_score(yval.values,yhat_val)\n",
    "test_auc = roc_auc_score(ytest.values,yhat_test)\n",
    "print('train_auc = ',train_auc)\n",
    "print('val_auc = ',val_auc)\n",
    "print('test_auc = ',test_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d01cd6-59dd-44bb-a7f0-27d6b1fe1dd9",
   "metadata": {},
   "source": [
    "## 三，Xlearn的速查列表\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e418481-3cb7-4d32-8cb1-93dc2d1e78ba",
   "metadata": {},
   "source": [
    "### 1，Xlearn的API列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5259d1-852c-4e98-b8ce-22089fd539b1",
   "metadata": {},
   "source": [
    "```python\n",
    "import xlearn as xl      # Import xlearn package\n",
    "\n",
    "xl.hello()               # Say hello to user\n",
    "\n",
    "#This part is for data\n",
    "#X is feautres data, can be pandas DataFrame or numpy.ndarray,\n",
    "#y is label, default None, can be pandas DataFrame\\Series, array or list,\n",
    "#filed_map is field map of features, default None, can be pandas DataFrame\\Series, array or list\n",
    "dmatrix = xl.DMatrix(X, y, field_map)\n",
    "\n",
    "model = create_linear()  #Create linear model.\n",
    "\n",
    "model = create_fm()      #Create factorization machines.\n",
    "\n",
    "model = create_ffm()     #Create field-aware factorizarion machines.\n",
    "\n",
    "model.show()             #Show model information.\n",
    "\n",
    "model.fit(param, \"model_path\")   #Train model.\n",
    "\n",
    "model.cv(param)    #Perform cross-validation.\n",
    "\n",
    "#Users can choose one of this two\n",
    "model.predict(\"model_path\", \"output_path\")  #Perform prediction, output result to file, return None.\n",
    "model.predict(\"model_path\")                 #Perform prediction, return result by numpy.ndarray.\n",
    "\n",
    "#Users can choose one of this two\n",
    "model.setTrain(\"data_path\")      #Set training data from file for xLearn.\n",
    "model.setTrain(dmatrix)          #Set training data from DMatrix for xLearn.\n",
    "\n",
    "#Users can choose one of this two\n",
    "#note: this type of validate must be same as train\n",
    "#that is, set train from file, must set validate from file\n",
    "model.setValidate(\"data_path\")   #Set validation data from file for xLearn.\n",
    "model.setValidate(dmatrix)       #Set validation data from DMatrix for xLearn.\n",
    "\n",
    "#Users can choose one of this two\n",
    "model.setTest(\"data_path\")       #Set test data from file for xLearn.\n",
    "model.setTest(dmatrix)           #Set test data from DMatrix for xLearn.\n",
    "\n",
    "model.setQuiet()    #Set xlearn to train model quietly.\n",
    "\n",
    "model.setOnDisk()   #Set xlearn to use on-disk training.\n",
    "\n",
    "model.setNoBin()    #Do not generate bin file for training and test data.\n",
    "\n",
    "model.setSign()     #Convert prediction to 0 and 1.\n",
    "\n",
    "model.setSigmoid()  #Convert prediction to (0, 1).\n",
    "\n",
    "model.disableNorm() #Disable instance-wise normalization.\n",
    "\n",
    "model.disableLockFree()   #Disable lock-free training.\n",
    "\n",
    "model.disableEarlyStop()  #Disable early-stopping.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ba1f2-4e23-403b-b58f-4b6591235041",
   "metadata": {},
   "source": [
    "### 2，Xlearn超参数列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19755439-88d0-4257-904a-cd2be668cf4d",
   "metadata": {},
   "source": [
    "```python\n",
    "task     : {'binary',  #Binary classification\n",
    "            'reg'}     #Regression\n",
    "\n",
    "metric   : {'acc', 'prec', 'recall', 'f1', 'auc',   #for classification\n",
    "            'mae', 'mape', 'rmse', 'rmsd'}  #for regression\n",
    "\n",
    "lr       : float value  #learning rate\n",
    "\n",
    "lambda   : float value  #regular lambda\n",
    "\n",
    "k        : int value    #latent factor for fm and ffm\n",
    "\n",
    "init     : float value  #model initialize\n",
    "\n",
    "alpha    : float value  #hyper parameter for ftrl\n",
    "\n",
    "beta     : float value  #hyper parameter for ftrl\n",
    "\n",
    "lambda_1 : float value  #hyper parameter for ftrl\n",
    "\n",
    "lambda_2 : float value  #hyper parameter for ftrl\n",
    "\n",
    "nthread  : int value    #the number of CPU cores\n",
    "\n",
    "epoch    : int vlaue    #number of epoch\n",
    "\n",
    "fold     : int value    #number of fold for cross-validation\n",
    "\n",
    "opt      : {'sgd', 'agagrad', 'ftrl'}  #optimization method\n",
    "\n",
    "stop_window : Size of stop window for early-stopping.\n",
    "\n",
    "block_size : int value  #block size for on-disk training\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
